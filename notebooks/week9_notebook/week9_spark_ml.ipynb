{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunset-provision",
   "metadata": {},
   "source": [
    "# Introduction to Spark ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-blood",
   "metadata": {},
   "source": [
    "## Predict chances of infant survival with ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local[4]').appName('spark_ml').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-chile",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-minnesota",
   "metadata": {},
   "source": [
    "First, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-holly",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "births = spark.read.options(inferSchema = True).csv('births_transformed.csv.gz', header=True)\n",
    "births.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-winning",
   "metadata": {},
   "source": [
    "### Create transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-custom",
   "metadata": {},
   "source": [
    "Having done this, we can now create our first `Transformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as types\n",
    "import pyspark.ml.feature as ft\n",
    "\n",
    "encoder = ft.OneHotEncoder(inputCol='BIRTH_PLACE', outputCol='BIRTH_PLACE_VEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-athens",
   "metadata": {},
   "source": [
    "Let's now create a single column with all the features collated together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCreator = ft.VectorAssembler(inputCols=[col for col in births.columns[2:]] + [encoder.getOutputCol()], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-marking",
   "metadata": {},
   "source": [
    "### Create an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-entry",
   "metadata": {},
   "source": [
    "In this example we will (once again) us the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.classification as cl\n",
    "logistic = cl.LogisticRegression(maxIter=10, regParam=0.01, labelCol='INFANT_ALIVE_AT_REPORT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-steam",
   "metadata": {},
   "source": [
    "### Create a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-movie",
   "metadata": {},
   "source": [
    "All that is left now is to creat a `Pipeline` and fit the model. First, let's load the `Pipeline` from the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-demographic",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[encoder, featuresCreator, logistic])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-circus",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-twist",
   "metadata": {},
   "source": [
    "Conventiently, `DataFrame` API has the `.randomSplit(...)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-sellers",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "births_train, births_test = births.randomSplit([0.7, 0.3], seed=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-housing",
   "metadata": {},
   "source": [
    "Now run our `pipeline` and estimate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-respect",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(births_train)\n",
    "test_model = model.transform(births_test)\n",
    "test_model.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-southeast",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-perfume",
   "metadata": {},
   "source": [
    "Obviously, we would like to now test how well our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-camping",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "\n",
    "evaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-browse",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-matthew",
   "metadata": {},
   "source": [
    "PySpark allows you to save the `Pipeline` definition for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-daily",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipeline_path = './Logistic_Pipeline'\n",
    "pipeline.write().overwrite().save(pipeline_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-proportion",
   "metadata": {},
   "source": [
    "So, you can load it up later and use straight away to `.fit(...)` and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-cattle",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loaded_pipeline = Pipeline.load(pipeline_path)\n",
    "loaded_pipeline.fit(births_train).transform(births_test).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-positive",
   "metadata": {},
   "source": [
    "You can also save the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "model_path = './Logistic_Model'\n",
    "model.write().overwrite().save(model_path)\n",
    "\n",
    "loaded_model = PipelineModel.load(model_path)\n",
    "loaded_model.transform(births_test).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-opposition",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-camera",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-disease",
   "metadata": {},
   "source": [
    "Load the `.tuning` part of the package. Specify our model and the list of parameters we want to loop through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning as tune\n",
    "logistic = cl.LogisticRegression(labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "\n",
    "grid = tune.ParamGridBuilder().addGrid(logistic.maxIter, [2, 10, 50]).addGrid(logistic.regParam, [0.01, 0.05, 0.3]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-question",
   "metadata": {},
   "source": [
    "Next, we need some way of comparing the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='INFANT_ALIVE_AT_REPORT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-influence",
   "metadata": {},
   "source": [
    "Create the logic that will do the validation work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = tune.CrossValidator(estimator=logistic, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-blanket",
   "metadata": {},
   "source": [
    "Create a purely transforming `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-scanner",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[encoder, featuresCreator])\n",
    "data_transformer = pipeline.fit(births_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-diameter",
   "metadata": {},
   "source": [
    "Having done this, we are ready to find the optimal combination of parameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-purple",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cvModel = cv.fit(data_transformer.transform(births_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-audio",
   "metadata": {},
   "source": [
    "The `cvModel` will return the best model estimated. We can now use it to see if it performed better than our previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-calibration",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_test = data_transformer.transform(births_test)\n",
    "results = cvModel.transform(data_test)\n",
    "\n",
    "print(evaluator.evaluate(results, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-friend",
   "metadata": {},
   "source": [
    "What parameters has the best model? The answer is a little bit convoluted but here's how you can extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.getEstimatorParamMaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-andorra",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for params, metric in zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics):\n",
    "    parameters = []\n",
    "    for key, paramValue in zip(params.keys(), params.values()):\n",
    "        parameters.append({key.name: paramValue})\n",
    "    results.append((parameters, metric))\n",
    "\n",
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-playlist",
   "metadata": {},
   "source": [
    "### Train-Validation splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-reviewer",
   "metadata": {},
   "source": [
    "Use the `ChiSqSelector` to select only top 5 features, thus limiting the complexity of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-flavor",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "selector = ft.ChiSqSelector(numTopFeatures=5, featuresCol=featuresCreator.getOutputCol(), outputCol='selectedFeatures', labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "\n",
    "logistic = cl.LogisticRegression(labelCol='INFANT_ALIVE_AT_REPORT', featuresCol='selectedFeatures')\n",
    "\n",
    "pipeline = Pipeline(stages=[encoder, featuresCreator, selector])\n",
    "feature_transformer = pipeline.fit(births_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-preview",
   "metadata": {},
   "source": [
    "The `TrainValidationSplit` object gets created in the same fashion as the `CrossValidator` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = tune.ParamGridBuilder().addGrid(logistic.maxIter, [2, 10, 50]).addGrid(logistic.regParam, [0.01, 0.05, 0.3]).build()\n",
    "tvs = tune.TrainValidationSplit(estimator=logistic, estimatorParamMaps=grid, evaluator=evaluator, collectSubModels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-school",
   "metadata": {},
   "source": [
    "As before, we fit our data to the model, and calculate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-married",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tvsModel = tvs.fit(feature_transformer.transform(births_train))\n",
    "\n",
    "data_test = feature_transformer.transform(births_test)\n",
    "results = tvsModel.transform(data_test)\n",
    "\n",
    "print(evaluator.evaluate(results, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvsModel.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for params, metric in zip(tvsModel.getEstimatorParamMaps(), tvsModel.validationMetrics):\n",
    "    parameters = []\n",
    "    for key, paramValue in zip(params.keys(), params.values()):\n",
    "        parameters.append({key.name: paramValue})\n",
    "    results.append((parameters, metric))\n",
    "\n",
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-wisdom",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-romantic",
   "metadata": {},
   "source": [
    "We will now use the `RandomForestClassfier` to model the chances of survival for an infant.\n",
    "\n",
    "First, we need to cast the label feature to `DoubleType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-variance",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.types as types\n",
    "\n",
    "births = births.withColumn('INFANT_ALIVE_AT_REPORT', fn.col('INFANT_ALIVE_AT_REPORT').cast(types.DoubleType()))\n",
    "births_train, births_test = births.randomSplit([0.7, 0.3], seed=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-southwest",
   "metadata": {},
   "source": [
    "We are ready to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-recipient",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "classifier = cl.RandomForestClassifier(numTrees=5, maxDepth=5, labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "pipeline = Pipeline(stages=[encoder, featuresCreator, classifier])\n",
    "model = pipeline.fit(births_train)\n",
    "test = model.transform(births_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-anthropology",
   "metadata": {},
   "source": [
    "Let's now see how the `RandomForestClassifier` model performs compared to the `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-convergence",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "evaluator = ev.BinaryClassificationEvaluator(labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "\n",
    "print(evaluator.evaluate(test, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "print(evaluator.evaluate(test, {evaluator.metricName: \"areaUnderPR\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-stevens",
   "metadata": {},
   "source": [
    "Let's test how well would one tree do, then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-shift",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "classifier = cl.DecisionTreeClassifier(maxDepth=5, labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "pipeline = Pipeline(stages=[encoder, featuresCreator, classifier])\n",
    "model = pipeline.fit(births_train)\n",
    "test = model.transform(births_test)\n",
    "\n",
    "evaluator = ev.BinaryClassificationEvaluator(labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "print(evaluator.evaluate(test, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "print(evaluator.evaluate(test, {evaluator.metricName: \"areaUnderPR\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-interpretation",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-spending",
   "metadata": {},
   "source": [
    "In this section we will try to predict the `MOTHER_WEIGHT_GAIN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['MOTHER_AGE_YEARS','MOTHER_HEIGHT_IN',\n",
    "            'MOTHER_PRE_WEIGHT','DIABETES_PRE',\n",
    "            'DIABETES_GEST','HYP_TENS_PRE', \n",
    "            'HYP_TENS_GEST', 'PREV_BIRTH_PRETERM',\n",
    "            'CIG_BEFORE','CIG_1_TRI', 'CIG_2_TRI', 'CIG_3_TRI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-mustang",
   "metadata": {},
   "source": [
    "First, we will collate all the features together and use the `ChiSqSelector` to select only the top 6 most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCreator = ft.VectorAssembler(inputCols=[col for col in features[1:]], outputCol='features')\n",
    "\n",
    "selector = ft.ChiSqSelector(numTopFeatures=5, outputCol=\"selectedFeatures\", labelCol='MOTHER_WEIGHT_GAIN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-calibration",
   "metadata": {},
   "source": [
    "In order to predict the weight gain we will use the gradient boosted trees regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.regression as reg\n",
    "regressor = reg.GBTRegressor(maxIter=15, maxDepth=3, labelCol='MOTHER_WEIGHT_GAIN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-refrigerator",
   "metadata": {},
   "source": [
    "Finally, again, we put it all together into a `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-father",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featuresCreator, selector, regressor])\n",
    "weight_gain = pipeline.fit(births_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-executive",
   "metadata": {},
   "source": [
    "Having created the `weight_gain` model, let's see if it performs well on our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-wesley",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "evaluator = ev.RegressionEvaluator(predictionCol=\"prediction\", labelCol='MOTHER_WEIGHT_GAIN')\n",
    "\n",
    "print(evaluator.evaluate(weight_gain.transform(births_test), {evaluator.metricName: 'r2'}))\n",
    "print(evaluator.evaluate(weight_gain.transform(births_test), {evaluator.metricName: 'rmse'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-franklin",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-front",
   "metadata": {},
   "source": [
    "In this example we will use k-means model to find similarities in the births data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.clustering as clus\n",
    "\n",
    "kmeans = clus.KMeans(k = 5, featuresCol='features')\n",
    "pipeline = Pipeline(stages=[encoder, featuresCreator, kmeans])\n",
    "model = pipeline.fit(births_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-titanium",
   "metadata": {},
   "source": [
    "Having estimated the model, let's see if we can find some differences between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = model.transform(births_train)\n",
    "train.groupBy('prediction').agg(fn.count('*'), fn.avg('MOTHER_HEIGHT_IN')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-building",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test = model.transform(births_test)\n",
    "test.groupBy('prediction').agg(fn.count('*'), fn.avg('MOTHER_HEIGHT_IN')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-beast",
   "metadata": {},
   "source": [
    "## Text Mining with Spark ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-psychology",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-netherlands",
   "metadata": {},
   "source": [
    "Here we use an Airbnb review dataset from all properties in Denver area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = spark.read.options(inferSchema = True, multiLine = True, escape = '\\\"').csv('reviews.csv.gz', header=True)\n",
    "reviews.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.dropna(subset=['comments'])\n",
    "reviews = reviews.withColumn('comments', fn.regexp_replace(fn.col(\"comments\"), '([^\\s\\w_]|_)+', ' ')).withColumn('comments', fn.regexp_replace(fn.col(\"comments\"), '[\\n\\r]', ' '))\n",
    "reviews.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-silver",
   "metadata": {},
   "source": [
    "First, we need to tokenize this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ft.RegexTokenizer(inputCol='comments', outputCol='comments_tok', pattern='\\s+|[,.\\\"/!]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-exemption",
   "metadata": {},
   "source": [
    "The output of the tokenizer looks similar to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-excitement",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tok = tokenizer.transform(reviews).select('comments_tok') \n",
    "tok.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-organizer",
   "metadata": {},
   "source": [
    "Use the `StopWordsRemover(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ft.StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='comments_stop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-essay",
   "metadata": {},
   "source": [
    "The output of the method looks as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-teens",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "stopwords.transform(tok).select('comments_stop').take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-parameter",
   "metadata": {},
   "source": [
    "Build `NGram` model and the `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = ft.NGram(n=2, inputCol=stopwords.getOutputCol(), outputCol=\"nGrams\")\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords, ngram])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-horizon",
   "metadata": {},
   "source": [
    "Now that we have the `pipeline` we follow in the very similar fashion as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-lodging",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_ngram = pipeline.fit(reviews).transform(reviews)\n",
    "data_ngram.select('nGrams').take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-carol",
   "metadata": {},
   "source": [
    "That's it. We got our n-grams and we can then use them in further NLP processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-sherman",
   "metadata": {},
   "source": [
    "First, we will once again use the `RegexTokenizer` and the `StopWordsRemover` models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-arrangement",
   "metadata": {},
   "source": [
    "Next to model text we have `CountVectorizer` in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-violin",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "stringIndexer = ft.CountVectorizer(inputCol=stopwords.getOutputCol(), outputCol=\"comments_indexed\")\n",
    "tokenized = stopwords.transform(tokenizer.transform(reviews))\n",
    "stringIndexer.fit(tokenized).transform(tokenized).select('comments_indexed').take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-details",
   "metadata": {},
   "source": [
    "We will use the `LDA` model - the Latent Dirichlet Allocation model - to extract the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.clustering as clus\n",
    "lda = clus.LDA(k=5, optimizer='online', featuresCol=stringIndexer.getOutputCol())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-trainer",
   "metadata": {},
   "source": [
    "Put these transformers and estimators together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-button",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer, stopwords, stringIndexer, lda])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-rendering",
   "metadata": {},
   "source": [
    "Let's see if we have properly uncovered the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-forwarding",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(reviews)\n",
    "topics = pipeline_model.transform(reviews)\n",
    "topics.select('topicDistribution').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized_model = stringIndexer.fit(tokenized)\n",
    "#vectorized = vectorized_model.transform(tokenized)\n",
    "#lda = clus.LDA(k=5, optimizer='online', featuresCol=stringIndexer.getOutputCol())\n",
    "#topic_model = lda.fit(vectorized)\n",
    "#topics = topic_model.transform(vectorized)\n",
    "#topics.select('topicDistribution').take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-quality",
   "metadata": {},
   "source": [
    "Now we want to know the topics. Here is how we extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_model = pipeline_model.stages[2]\n",
    "topic_model = pipeline_model.stages[3]\n",
    "topic_model.describeTopics(10).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-fisher",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = vectorized_model.vocabulary\n",
    "topic_words_list = topic_model.describeTopics(10)\n",
    "\n",
    "topic_words_rdd = topic_words_list.rdd\n",
    "topics_words = topic_words_rdd.map(lambda row: row['termIndices']).map(lambda idx_list: [vocab[idx] for idx in idx_list]).collect()\n",
    "\n",
    "for idx, topic in enumerate(topics_words):\n",
    "    print(\"topic: {}\".format(idx))\n",
    "    print(\"*\"*25)\n",
    "    for word in topic:\n",
    "       print(word)\n",
    "    print(\"*\"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = ft.CountVectorizer(inputCol=ngram.getOutputCol(), outputCol=\"comments_n_indexed\")\n",
    "nlda = clus.LDA(k=5, optimizer='online', featuresCol=stringIndexer.getOutputCol())\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords, ngram, stringIndexer, nlda])\n",
    "\n",
    "pipeline_model = pipeline.fit(reviews)\n",
    "topics = pipeline_model.transform(reviews)\n",
    "topics.select('topicDistribution').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_vectorized_model = stringIndexer.fit(data_ngram)\n",
    "#n_vectorized = n_vectorized_model.transform(data_ngram)\n",
    "\n",
    "#n_topic_model = nlda.fit(n_vectorized)\n",
    "#n_topics = n_topic_model.transform(n_vectorized)\n",
    "#n_topics.select('topicDistribution').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-ethiopia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_vectorized_model = pipeline_model.stages[3]\n",
    "n_topic_model = pipeline_model.stages[4]\n",
    "\n",
    "vocab = n_vectorized_model.vocabulary\n",
    "n_topic_words_list = n_topic_model.describeTopics(10)\n",
    "\n",
    "n_topic_words_rdd = n_topic_words_list.rdd\n",
    "n_topics_words = n_topic_words_rdd.map(lambda row: row['termIndices']).map(lambda idx_list: [vocab[idx] for idx in idx_list]).collect()\n",
    "\n",
    "for idx, topic in enumerate(n_topics_words):\n",
    "    print(\"topic: {}\".format(idx))\n",
    "    print(\"*\"*25)\n",
    "    for word in topic:\n",
    "       print(word)\n",
    "    print(\"*\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-allah",
   "metadata": {},
   "source": [
    "Last we use TF-IDF to train topic model; it is not always useful to train LDA with TF-IDF, as sometimes TF is sufficient. Here we just try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use tf-idf vector\n",
    "tf = ft.CountVectorizer(inputCol=stopwords.getOutputCol(), outputCol=\"comments_tf\")\n",
    "idf = ft.IDF(inputCol=tf.getOutputCol(), outputCol=\"comments_tfidf\")\n",
    "lda = clus.LDA(k=5, optimizer='online', maxIter=10, featuresCol=idf.getOutputCol())\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords, tf, idf, lda])\n",
    "pipeline_model = pipeline.fit(reviews)\n",
    "\n",
    "topics = pipeline_model.transform(reviews)\n",
    "topics.select('topicDistribution').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-pilot",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_model = pipeline_model.stages[2]\n",
    "topic_model = pipeline_model.stages[4]\n",
    "vocab = tf_model.vocabulary\n",
    "topic_words_list = topic_model.describeTopics(20)\n",
    "topic_words_rdd = topic_words_list.rdd\n",
    "topics_words = topic_words_rdd.map(lambda row: row['termIndices']).map(lambda idx_list: [vocab[idx] for idx in idx_list]).collect()\n",
    "\n",
    "for idx, topic in enumerate(topics_words):\n",
    "    print(\"topic: {}\".format(idx))\n",
    "    print(\"*\"*25)\n",
    "    for word in topic:\n",
    "       print(word)\n",
    "    print(\"*\"*25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

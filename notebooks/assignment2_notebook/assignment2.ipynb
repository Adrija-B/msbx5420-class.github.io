{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSBX 5420 Assignment 2\n",
    "## Task 1 - Warm Up with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate the MapReduce Calculations in Assignment 1 with Spark RDD, DataFrame and SQL\n",
    "As a warm-up, your first task will be replicating the same MapReduce jobs in assignment 1 with spark RDD and DataFrame/SQL.\n",
    "First, let's load the NFL dataset into Spark. For convenience we will use spark session and dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#let's use all cores with 'local[*]' to somehow speed up\n",
    "spark = SparkSession.builder.master('local[*]').appName('spark_nfl_data').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the NFL dataset, those missing values we have tried to skip in assignment 1 are \"NA\". By default, spark will treat empty or null as missing values, so here we need to let spark treat \"NA\" as the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nfl = spark.read.options(header=True, nullValue='NA', inferSchema=True).csv('./NFL_Play_by_Play_2009-2018.csv')\n",
    "df_nfl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check and clean the data with dataframe\n",
    "print(df_nfl.count())\n",
    "print(df_nfl.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate rows\n",
    "df_nfl = df_nfl.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data\n",
    "df_nfl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the dta via pandas\n",
    "import pandas as pd\n",
    "#disable the row/column limits to not truncate the displayed data\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_nfl.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's also see the number of partitions\n",
    "df_nfl.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dataset to a RDD\n",
    "rdd_nfl = df_nfl.rdd\n",
    "rdd_nfl.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the RDD converted from Dataframe so we can do RDD operations with `rdd_nfl`. Now let's replicate the two calculations (1) number of plays in each game (2) average yarns gained in each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapreduce with spark RDD for sum of plays\n",
    "#[Your Code]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapreduce with spark RDD for average yards gained\n",
    "#hint: there are \"NA\"s (None) in the column \"yards_gained\"; after into dataframe and transformed as RDD, \"NA\" is None now, and others are integers\n",
    "#[Your Code]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's do it with spark dataframe and SQL. The dataframe is `df_nfl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use dataframe operations/api\n",
    "#[Your Code]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use spark sql - don't forget to create temp view for df_nfl before querying the dataframe\n",
    "#[Your Code]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Data Analytics with Spark DataFrame and SQL\n",
    "### Answer four data analytics questions on NFL dataset to solve the problems\n",
    "With the NFL Dataframe `df_nfl`, use either dataframe operations/API or spark SQL to answer the following questions.\n",
    "First of all, let's build a data viewer to look at the data so we can understand the values better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a data viewer to check data for a game; the list basically contains all the columns to use in this task\n",
    "game_info_all = ['play_id', 'game_id', 'home_team', 'away_team', 'game_date', \n",
    "                 'posteam', 'posteam_type', 'defteam',\n",
    "                 'total_home_score', 'total_away_score',\n",
    "                 'touchdown', 'pass_touchdown', 'rush_touchdown', 'return_touchdown']\n",
    "#df_nfl.select(game_info).limit(200).toPandas().head(200)\n",
    "df_nfl.select(game_info_all).where('game_id = 2018111110').toPandas().head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are going to answer the following questions using spark dataframe or spark SQL. You can choose either one to solve the problem and output results.\n",
    "1. Which game(s) has the highest number of plays from 2009 to 2018? And which game has the highest final score difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import Window\n",
    "\n",
    "#you need to show the game info with the highest plays, so let's obtain game level information\n",
    "game_info = ['game_id', 'home_team', 'away_team', 'game_date', 'total_home_score', 'total_away_score']\n",
    "#because we need the final scores for each game as game level info, we can do that by filtering the maxiumn play id to get game level info\n",
    "window = Window.partitionBy('game_id')\n",
    "nfl_game_info = df_nfl.withColumn(\"max_play_id\", fn.max(\"play_id\").over(window)).filter(\"max_play_id = play_id\").drop(\"max_play_id\").select(game_info)\n",
    "nfl_game_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of plays in each game\n",
    "nfl_num_play = df_nfl.groupBy('game_id').agg(fn.count('play_id').alias('num_plays'))\n",
    "nfl_num_play.show()\n",
    "\n",
    "#join the two dataframes\n",
    "nfl_game_info = nfl_game_info.join(nfl_num_play, 'game_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Your Code] to get the game with highest number of plays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now it is the score difference\n",
    "nfl_game_info = nfl_game_info.withColumn('score_diff', fn.abs(nfl_game_info['total_home_score'] - nfl_game_info['total_away_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Your Code] to get the game with highest score difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. On average how many plays are needed for a successful touchdown? And how many plays are needed for home team and away team, respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_game_play = df_nfl.groupBy('game_id').agg(fn.count('play_id').alias('total_plays'), fn.sum('touchdown').alias('total_touchdowns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Your Code] to take average for total_plays/total_touchdowns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_team_play = df_nfl.groupBy('game_id', 'posteam_type').agg(fn.count('play_id').alias('total_plays'), fn.sum('touchdown').alias('total_touchdowns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Your Code] to take average for total_plays/total_touchdowns by posteam_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For touchdown, which type happened more likely on average, rush touchdown, pass touchdown or return touchdown? Are the probabilities different by home and away team?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Your Code] to calculate total touchdowns and total of each type of touchdowns by game\n",
    "#then take average for each type of touchdown divided by total touchdowns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Your Code] to calculate total touchdowns and total of each type of touchdowns by game and posteam_type\n",
    "#then take average for each type of touchdown divided by total touchdowns by posteam_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For each calendar year, which team(s) has the highest winning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the available teams\n",
    "df_nfl.select('home_team').distinct().show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_game_info = nfl_game_info.withColumn('win_team', fn.when(fn.col('total_home_score') > fn.col('total_away_score'), fn.col('home_team')).otherwise(fn.col('away_team')))\n",
    "nfl_game_info = nfl_game_info.withColumn('game_year', fn.substring('game_date', 0, 4))\n",
    "nfl_game_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create three sub dataframe, by team-year\n",
    "win_count = nfl_game_info.groupBy(fn.col('win_team').alias('team'), 'game_year').agg(fn.count('win_team').alias('win_count'))\n",
    "home_count = nfl_game_info.groupBy(fn.col('home_team').alias('team'), 'game_year').agg(fn.count('home_team').alias('home_count'))\n",
    "away_count = nfl_game_info.groupBy(fn.col('away_team').alias('team'), 'game_year').agg(fn.count('away_team').alias('away_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Your Code] to join the three dataframes by 'team' for subsequent calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate total game counts and winning rate\n",
    "team_count = team_count.withColumn('game_count', team_count['home_count'] + team_count['away_count'])\n",
    "team_count = team_count.withColumn('win_rate', team_count['win_count'] / team_count['game_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Your Code] to obtain the team(s) with highest winning rate in each calendar year\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep learning example for Covolutional Neural Network\n",
    "#dataset url\n",
    "#!wget https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/hotdog.zip\n",
    "#!unzip hotdog.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImgClassifier, self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        #torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        #input dimensions [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),    #[64, 128, 128]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),        #[64, 64, 64]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),  #[128, 64, 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),        #[128, 32, 32]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), #[256, 32, 32]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),        #[256, 16, 16]\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), #[512, 16, 16]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),        #[512, 8, 8]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1), #[512, 8, 8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),        #[512, 4, 4]\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of neural network\n",
    "model = ImgClassifier()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "#loss = nn.CrossEntropyLoss()\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Size of training data = 2000\n",
      "Size of testing data = 800\n"
     ]
    }
   ],
   "source": [
    "def readfile(path):\n",
    "    #read hotdog folder\n",
    "    hotdog_dir = sorted(os.listdir(path+'/hotdog'))\n",
    "    not_hotdog_dir = sorted(os.listdir(path+'/not-hotdog'))\n",
    "    x = np.zeros((len(hotdog_dir)+len(not_hotdog_dir), 128, 128, 3), dtype=np.uint8)\n",
    "    y = np.zeros((len(hotdog_dir)+len(not_hotdog_dir)), dtype=np.uint8)\n",
    "    \n",
    "    for i, file in enumerate(hotdog_dir):\n",
    "        img = cv2.imread(os.path.join(path+'/hotdog', file))\n",
    "        x[i, :, :] = cv2.resize(img,(128, 128))\n",
    "        y[i] = 1\n",
    "\n",
    "    for i, file in enumerate(not_hotdog_dir):\n",
    "        img = cv2.imread(os.path.join(path+'/not-hotdog', file))\n",
    "        x[i+len(hotdog_dir), :, :] = cv2.resize(img,(128, 128))\n",
    "        y[i+len(hotdog_dir)] = 0\n",
    "    \n",
    "    return x, y\n",
    "             \n",
    "#read training and testing data\n",
    "print(\"Reading data\")\n",
    "train_x, train_y = readfile('./hotdog/train')\n",
    "print(\"Size of training data = {}\".format(len(train_x)))\n",
    "test_x, test_y = readfile('./hotdog/test')\n",
    "print(\"Size of testing data = {}\".format(len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                      \n",
    "    transforms.ToTensor(),])\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        # label is required to be a LongTensor\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImgDataset(train_x, train_y, train_transform)\n",
    "test_set = ImgDataset(test_x, test_y, test_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16)\n",
    "\n",
    "def evaluation(outputs, labels):\n",
    "    outputs[outputs>=0.5] = 1\n",
    "    outputs[outputs<0.5] = 0\n",
    "    correct = torch.sum(torch.eq(outputs, labels)).item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/030] 14.79 sec(s) Train Acc: 0.780000 Loss: 0.035036 | Val Acc: 0.828750 loss: 0.024481\n",
      "[002/030] 9.18 sec(s) Train Acc: 0.830500 Loss: 0.024508 | Val Acc: 0.872500 loss: 0.021771\n",
      "[003/030] 9.16 sec(s) Train Acc: 0.842500 Loss: 0.024029 | Val Acc: 0.875000 loss: 0.020952\n",
      "[004/030] 9.17 sec(s) Train Acc: 0.863500 Loss: 0.022683 | Val Acc: 0.871250 loss: 0.022598\n",
      "[005/030] 9.21 sec(s) Train Acc: 0.861000 Loss: 0.021379 | Val Acc: 0.857500 loss: 0.022445\n",
      "[006/030] 9.71 sec(s) Train Acc: 0.869000 Loss: 0.020363 | Val Acc: 0.883750 loss: 0.017537\n",
      "[007/030] 10.01 sec(s) Train Acc: 0.881500 Loss: 0.018063 | Val Acc: 0.887500 loss: 0.017079\n",
      "[008/030] 10.60 sec(s) Train Acc: 0.883000 Loss: 0.018008 | Val Acc: 0.776250 loss: 0.034436\n",
      "[009/030] 10.46 sec(s) Train Acc: 0.899000 Loss: 0.017258 | Val Acc: 0.875000 loss: 0.021093\n",
      "[010/030] 10.95 sec(s) Train Acc: 0.890500 Loss: 0.017475 | Val Acc: 0.860000 loss: 0.021059\n",
      "[011/030] 11.16 sec(s) Train Acc: 0.878000 Loss: 0.017938 | Val Acc: 0.875000 loss: 0.020683\n",
      "[012/030] 10.38 sec(s) Train Acc: 0.889500 Loss: 0.017865 | Val Acc: 0.852500 loss: 0.022913\n",
      "[013/030] 10.12 sec(s) Train Acc: 0.898500 Loss: 0.016175 | Val Acc: 0.833750 loss: 0.028804\n",
      "[014/030] 9.94 sec(s) Train Acc: 0.903500 Loss: 0.015181 | Val Acc: 0.880000 loss: 0.019334\n",
      "[015/030] 9.88 sec(s) Train Acc: 0.899000 Loss: 0.016826 | Val Acc: 0.896250 loss: 0.017486\n",
      "[016/030] 9.81 sec(s) Train Acc: 0.906000 Loss: 0.015246 | Val Acc: 0.892500 loss: 0.017627\n",
      "[017/030] 9.94 sec(s) Train Acc: 0.896500 Loss: 0.015722 | Val Acc: 0.883750 loss: 0.020531\n",
      "[018/030] 9.90 sec(s) Train Acc: 0.897000 Loss: 0.016273 | Val Acc: 0.871250 loss: 0.018242\n",
      "[019/030] 9.78 sec(s) Train Acc: 0.916000 Loss: 0.014229 | Val Acc: 0.890000 loss: 0.018517\n",
      "[020/030] 9.87 sec(s) Train Acc: 0.905500 Loss: 0.015634 | Val Acc: 0.883750 loss: 0.019946\n",
      "[021/030] 9.76 sec(s) Train Acc: 0.910000 Loss: 0.013728 | Val Acc: 0.767500 loss: 0.030966\n",
      "[022/030] 9.56 sec(s) Train Acc: 0.911000 Loss: 0.013447 | Val Acc: 0.861250 loss: 0.019591\n",
      "[023/030] 9.76 sec(s) Train Acc: 0.913500 Loss: 0.013554 | Val Acc: 0.823750 loss: 0.028724\n",
      "[024/030] 9.83 sec(s) Train Acc: 0.918000 Loss: 0.013334 | Val Acc: 0.891250 loss: 0.017379\n",
      "[025/030] 9.55 sec(s) Train Acc: 0.913000 Loss: 0.014207 | Val Acc: 0.888750 loss: 0.020680\n",
      "[026/030] 9.74 sec(s) Train Acc: 0.927000 Loss: 0.012194 | Val Acc: 0.902500 loss: 0.015870\n",
      "[027/030] 10.19 sec(s) Train Acc: 0.924000 Loss: 0.011729 | Val Acc: 0.888750 loss: 0.020552\n",
      "[028/030] 9.81 sec(s) Train Acc: 0.932500 Loss: 0.011521 | Val Acc: 0.883750 loss: 0.020319\n",
      "[029/030] 9.58 sec(s) Train Acc: 0.930000 Loss: 0.011598 | Val Acc: 0.855000 loss: 0.021519\n",
      "[030/030] 9.59 sec(s) Train Acc: 0.922500 Loss: 0.011682 | Val Acc: 0.903750 loss: 0.015644\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device, dtype=torch.float)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_predicted = model.forward(inputs)\n",
    "        train_predicted = train_predicted.squeeze()\n",
    "        batch_loss = loss(train_predicted, labels)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = evaluation(train_predicted, labels)\n",
    "        train_acc += correct\n",
    "        train_loss += batch_loss.item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device, dtype=torch.float)\n",
    "            \n",
    "            test_predicted = model.forward(inputs)\n",
    "            test_predicted = test_predicted.squeeze()\n",
    "            batch_loss = loss(test_predicted, labels)\n",
    "\n",
    "            correct = evaluation(test_predicted, labels)\n",
    "            test_acc += correct\n",
    "            test_loss += batch_loss.item()\n",
    "\n",
    "        #print result for each epoch\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, epochs, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), test_acc/test_set.__len__(), test_loss/test_set.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model save and load\n",
    "torch.save(model.state_dict(), './cnn_model.pt')\n",
    "model = ImgClassifier()\n",
    "model.load_state_dict(torch.load('./cnn_model.pt'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate final predictions\n",
    "prediction = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "\n",
    "        test_predicted = model.forward(inputs)\n",
    "        test_predicted = test_predicted.squeeze()\n",
    "        test_predicted[test_predicted>=0.5]=1\n",
    "        test_predicted[test_predicted<0.5]=0\n",
    "        test_label = test_predicted.cpu().data.numpy()\n",
    "        for y in test_label:\n",
    "            prediction.append(y)\n",
    "        \n",
    "with open(\"prediction.csv\", 'w') as f:\n",
    "    f.write('Id,Category\\n')\n",
    "    for i, y in  enumerate(prediction):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.9300e-05, 1.3235e-02, 8.3172e-01, 4.6780e-01, 1.0017e-01, 1.0156e-03,\n",
      "        8.3702e-02, 4.0218e-06], device='cuda:0')\n",
      "[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "tensor([0.2384, 0.9728, 0.9912, 0.1810], device='cuda:0')\n",
      "[0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "#generate predictions for some new images\n",
    "\n",
    "#read test_new folder\n",
    "test_dir = sorted(os.listdir('./hotdog/test_new'))\n",
    "test_new_x = np.zeros((len(test_dir), 128, 128, 3), dtype=np.uint8)\n",
    "\n",
    "for i, file in enumerate(test_dir):\n",
    "    img = cv2.imread(os.path.join('./hotdog/test_new', file))\n",
    "    test_new_x[i, :, :] = cv2.resize(img,(128, 128))\n",
    "\n",
    "test_new_set = ImgDataset(test_new_x, transform=test_transform)\n",
    "test_new_loader = DataLoader(test_new_set, batch_size=8)\n",
    "\n",
    "prediction = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_new_loader):\n",
    "        inputs = data.to(device)\n",
    "\n",
    "        test_predicted = model.forward(inputs)\n",
    "        test_predicted = test_predicted.squeeze()\n",
    "        print(test_predicted)\n",
    "        test_predicted[test_predicted>=0.5]=1\n",
    "        test_predicted[test_predicted<0.5]=0\n",
    "        test_label = test_predicted.cpu().data.numpy()\n",
    "        print(test_label)\n",
    "        for y in test_label:\n",
    "            prediction.append(y)\n",
    "        \n",
    "with open(\"prediction_new.csv\", 'w') as f:\n",
    "    f.write('Id,Category\\n')\n",
    "    for i, y in  enumerate(prediction):\n",
    "        f.write('{},{}\\n'.format(test_dir[i], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

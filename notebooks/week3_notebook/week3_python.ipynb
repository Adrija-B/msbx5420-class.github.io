{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Python Review\n",
    "## 1.1 Pandas\n",
    "We will first review some basic usage of pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first import pandas\n",
    "import pandas as pd\n",
    "#read data from csv\n",
    "dataset = pd.read_csv('./world_population.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**   \n",
    "`.iloc()` and `.loc()` are two important methods when indexing with Pandas. They allow to make precise selections of data based on either the integer value index (`iloc`) or the index column (`loc`), which in our case is the country name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate the USA row\n",
    "dataset.loc[[\"United States\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate rows Germany, Singapore, United States, and India \n",
    "dataset.loc[[\"Germany\", \"Singapore\", \"United States\", \"India\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate the last second to last row by index\n",
    "dataset.iloc[[-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the column of 2000\n",
    "dataset[\"2000\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate countries of rows 2 to 5\n",
    "dataset.iloc[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset of Germany, Singapore, United States, and India \n",
    "#for years 1970, 1990, 2010\n",
    "country_list = [\"Germany\", \"Singapore\", \"United States\", \"India\"]\n",
    "dataset.loc[country_list][[\"1970\", \"1990\", \"2010\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the mean of the third row\n",
    "dataset.iloc[[2]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the mean of the last row\n",
    "dataset.iloc[[-1]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the mean of the country Germany\n",
    "dataset.loc[[\"Germany\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter columns 1961, 2000, and 2015\n",
    "dataset.filter(items=[\"1961\", \"2000\", \"2015\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter countries that had a greater population density than 500 in 2000\n",
    "dataset[(dataset[\"2000\"] > 500)][[\"2000\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Advanced Python\n",
    "## 2.1 JSON\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load JSON File in Python\n",
    "Before starting to load files, you will first need to uncompress the structured-2018-01-14-neworleans.tar.gz file. Then the json files are available under the structured-2018-01-14-neworleans folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#you can compile the directory here\n",
    "datadir = os.path.join('./', 'structured-2018-01-14-neworleans')\n",
    "\n",
    "#let's load one of the json files\n",
    "jsonfile = 'structured-1515984523-6592b573-b485-58b0-963e-6be0b4d02f6c.json'\n",
    "\n",
    "#create the full file path\n",
    "jsonpath = os.path.join(datadir, jsonfile)\n",
    "print(jsonpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can open the file and read the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file\n",
    "with open(jsonpath, 'r') as f:\n",
    "    rawdata = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the rawdata\n",
    "rawdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the JSON file readable\n",
    "\n",
    "We have the raw text read in as a string, but we want to \"unpack\" it to make the into a readable format. We also call this \"deserialization\".\n",
    "\n",
    "Let's start with the standard json library, then followed by ujson, a faster library for json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is essentially a nested dictionary. Let's compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpledict = {\"a\": 1, \"b\": 2}\n",
    "simpledict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, the values can themselves be dicts and lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nesteddict = {\"a\": [5, 6, 7], \"b\": {\"dogs\": 10, \"cats\": 11}}\n",
    "nesteddict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['platform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestamps are often stored as \"unix timestamps\"\n",
    "#it is the number of seconds elapsed since Jan 1, 1970\n",
    "data['start_time_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['end_time_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['end_time_s'] - data['start_time_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the duration\n",
    "data['duration_ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['teams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['teams'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['teams'][0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['players']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['players'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you don't have ujson, you can install it\n",
    "!pip install ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try ujson, which is similar but faster for larger data\n",
    "import ujson\n",
    "data = ujson.loads(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write json object to disk\n",
    "with open('./match.json', 'w') as f:\n",
    "    ujson.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Lambda Function\n",
    "Here we will start with some simple artifical examples to know the basics of lambda (anonymous) function.\n",
    "We then use another dataset with pandas to know how to apply lambda function in data analysis.\n",
    "\n",
    "Lambda function in Python can be expressed as:\n",
    "```lambda argument_list:expersion```\n",
    "\n",
    "### Simple Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a simple example\n",
    "#define a function sq\n",
    "def sq(x):\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map(function, interator)\n",
    "#map is to apply with function on all the elements in the iterator\n",
    "list(map(sq, [y for y in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the same process can be done by lambda function lambda x: x*x\n",
    "list(map(lambda x:x*x, [y for y in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can assign the anonymous function to a variable\n",
    "c=lambda x,y,z:x*y*z\n",
    "c(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it can even be called directly\n",
    "(lambda x:x**2)(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter data with lambda function\n",
    "list(filter(lambda x: x%3==0, [1,2,3,4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter data with lambda function\n",
    "Names = ['Anne', 'Amy', 'Bob', 'David', 'Carrie', 'Barbara', 'Zach']\n",
    "\n",
    "#filter those names starting with B\n",
    "B_Name= list(filter(lambda x: x.startswith('B'), Names))\n",
    "print(B_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you will use map() in spark, here is another example\n",
    "squares = map(lambda x:x**2, range(5))\n",
    "list(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use lambda with reduce() function\n",
    "from functools import reduce\n",
    "print(reduce(lambda a,b:'{},{}'.format(a,b), [1,2,3,4,5,6,7,8,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reduce(lambda a,b:a+b, [1,2,3,4,5,6,7,8,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort data\n",
    "a=[('b',3),('a',2),('d',4),('c',1)]\n",
    "\n",
    "#sort by the key\n",
    "sorted(a, key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by the value\n",
    "sorted(a, key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add two lists together\n",
    "a = [1,2,3,4]\n",
    "b = [5,6,7,8]\n",
    "print(list(map(lambda x,y:x+y, a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Welcome To University of Colorado Boulder!\"\n",
    "words = sentence.split()\n",
    "lengths  = map(lambda x:len(x), words)\n",
    "print(list(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Lambda Function in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a dataset to apply lambda function\n",
    "dataset = pd.read_csv('./olympia2016_athletes.csv')\n",
    "#check the data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's first obtain the year of birth for player\n",
    "#we can define a function\n",
    "def dob_trans(player):\n",
    "    dob = str(player[4])\n",
    "    yr = dob[-2:]\n",
    "    return yr\n",
    "\n",
    "dataset['yr_1'] = dataset.apply(dob_trans, axis = 1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use lambda function\n",
    "dataset['yr_2'] = dataset.apply(lambda x:str(x[4])[-2:], axis = 1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we want to transform the gender column to a single character\n",
    "#we can define a function\n",
    "def gender_trans(player):\n",
    "    gender = player[3]\n",
    "    if gender == \"female\":\n",
    "        return \"F\"\n",
    "    elif gender == \"male\":\n",
    "        return \"M\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "dataset['gender_trans_1'] = dataset.apply(gender_trans, axis = 1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**  \n",
    "Using if/elif/else is pretty complicated in lambda function, but sometimes it saves a lot of efforts for writing separate functions. Here are the code structure for using if/elif/else in lambda:\n",
    "\n",
    "```lambda <arguments> : <Return Value if condition is True> if <condition> else <Return Value if condition is False>```\n",
    "\n",
    "```lambda <args> : <return Value> if <condition > else ( <return value > if <condition> else <return value>)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use lambda function\n",
    "dataset['gender_trans_2'] = dataset.apply(lambda x: \"F\" if x[3]==\"female\" else (\"M\" if x[3]==\"male\" else \"\"), axis = 1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Parquet File\n",
    "Here we will use pandas to save and load parquet files. Later on we will also use spark to save and load parquet files. Their logics are pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you will need pyarrow to support parquet then use pandas\n",
    "#for convenience, you can do pip in notebook directly\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#read a csv data and write to parquet\n",
    "df = pd.read_csv('./olympia2016_athletes.csv')\n",
    "df.to_parquet('./olympia2016_athletes.parquet')\n",
    "#on your disk you can see the parquet file, it is smaller than your csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from parquet format\n",
    "df = pd.read_parquet('./olympia2016_athletes.parquet')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
